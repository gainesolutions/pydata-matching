{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Real-World MDM: Mastering Hospital Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1 - Acquire the data and load it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Raw Datasets:\n",
    "\n",
    "[**CMS** (Centers for Medicare & Medicaid Services)](https://www.cms.gov/Research-Statistics-Data-and-Systems/Downloadable-Public-Use-Files/Provider-of-Services/index) (Select the \"Current California Healthcare Facility Listing\" file)\n",
    "\n",
    "\n",
    "[**OSHPD** (Office of Statewide Health Planning and Development)](https://data.chhs.ca.gov/dataset/licensed-healthcare-facility-listing) (Select the \"POS Other CSV\" file)\n",
    "\n",
    "\n",
    "*Note: Apologies if my Python is clunky. I'm relatively new to it. If you can improve it, please submit a pull request or talk to me afterward. I'd love to learn!*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oshpd = pd.read_csv(\"data/oshpd.csv\")\n",
    "cms = pd.read_csv(\"data/cms.csv\")  #Note - I modified this file from raw. It was limited to only rows where STATE_CD = \"CA\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oshpd.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cms.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2 - Analyze and Map the Data\n",
    "\n",
    "*Woof, look at those column names. And 473 of them.*\n",
    "\n",
    "***Tip #1:*** Know your data. Always ask for a data dictionary. (cms_data_dictionary.txt)\n",
    "\n",
    "***Tip #1:*** Don't get distracted by unnecessary data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# After studying the data dictionary, we take just the columns that we need.\n",
    "\n",
    "oshpd_simple = oshpd[[\n",
    "    \"OSHPD_ID\",\n",
    "    \"FACILITY_NAME\",\n",
    "    \"DBA_ADDRESS1\",\n",
    "    \"DBA_CITY\",\n",
    "    \"DBA_ZIP_CODE\"]]\n",
    "\n",
    "cms_simple = cms[[\n",
    "    \"PRVDR_NUM\",\n",
    "    \"FAC_NAME\",\n",
    "    \"ST_ADR\",\n",
    "    \"CITY_NAME\",\n",
    "    \"STATE_CD\",\n",
    "    \"ZIP_CD\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map OSHPD into a standard format\n",
    "\n",
    "# Convert to a dictionaries for easier transforms\n",
    "oshpd_dict = oshpd_simple.to_dict(orient=\"records\")\n",
    "cms_dict = cms_simple.to_dict(orient=\"records\")\n",
    "\n",
    "mapped = []\n",
    "\n",
    "# Map OSHPD to a new list of dictionaries\n",
    "for row in oshpd_dict:\n",
    "    newrow = {\n",
    "        \"pkey\":           \"oshpd.\" + str(row[\"OSHPD_ID\"]),\n",
    "        \"source\":         \"oshpd\",\n",
    "        \"source_id\":      row[\"OSHPD_ID\"],\n",
    "        \"oshpd_id\":       row[\"OSHPD_ID\"],\n",
    "        \"name\":           row[\"FACILITY_NAME\"],\n",
    "        \"address_line_1\": row[\"DBA_ADDRESS1\"],\n",
    "        \"city\":           row[\"DBA_CITY\"],\n",
    "        \"region\":         \"CA\",\n",
    "        \"post_code\":      row[\"DBA_ZIP_CODE\"]\n",
    "    }\n",
    "    mapped.append(newrow)\n",
    "    \n",
    "# Append CMS to that list of dictionaries\n",
    "for row in cms_dict:\n",
    "    newrow = {\n",
    "        \"pkey\":           \"cms.\" + str(row[\"PRVDR_NUM\"]),\n",
    "        \"source\":         \"cms\",\n",
    "        \"source_id\":      row[\"PRVDR_NUM\"],\n",
    "        \"cms_id\":         row[\"PRVDR_NUM\"],\n",
    "        \"name\":           row[\"FAC_NAME\"],\n",
    "        \"address_line_1\": row[\"ST_ADR\"],\n",
    "        \"city\":           row[\"CITY_NAME\"],\n",
    "        \"region\":         row[\"STATE_CD\"],\n",
    "        \"post_code\":      row[\"ZIP_CD\"]\n",
    "    }\n",
    "    mapped.append(newrow)\n",
    "\n",
    "df = pd.DataFrame(mapped).set_index(\"pkey\")[[\n",
    "        \"source\",\n",
    "        \"source_id\",\n",
    "        \"name\",\n",
    "        \"oshpd_id\",\n",
    "        \"cms_id\",\n",
    "        \"address_line_1\",\n",
    "        \"city\",\n",
    "        \"region\",\n",
    "        \"post_code\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do we see any dupes?\n",
    "\n",
    "df.sort_values(by=\"name\").head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Explore the Data**\n",
    "\n",
    "_Do you see any duplicates?_\n",
    "\n",
    "_How did you determine if two records were the same?_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3 - Cleanse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eliminate periods in the name and address\n",
    "df[\"name\"] = df[\"name\"].str.replace(\".\", \"\")\n",
    "df[\"address_line_1\"] = df[\"address_line_1\"].str.replace(\".\", \"\")\n",
    "\n",
    "# Lots more you can do, but we'll leave it at that\n",
    "\n",
    "df.sample(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 4 - Match\n",
    "\n",
    "Every row needs to be compared to every other row to see if it's a strong match.\n",
    "\n",
    "We'll run a simple match rule that says if Name + City + State are equal, they are a match."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform a self join, then limit the results to only those where Name, City, State are equal\n",
    "\n",
    "df_noindex = df.reset_index()\n",
    "\n",
    "matches = df_noindex.merge(df_noindex, how=\"inner\", on=[\"name\", \"city\", \"region\"])[[\"pkey_x\", \"pkey_y\"]]\n",
    "matches.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A Mathy Aside....\n",
    "This type of matching is an _equality relation_\n",
    "\n",
    "Equality means:\n",
    "\n",
    "* **Reflexive:** (A = A)\n",
    "* **Symmetric:** A = B ==> B = A\n",
    "* **Transitive:** A = B && B = C ==> A = C\n",
    "\n",
    "We can see self-matches and symmetric matches in the data above. But that's not very useful, so let's get rid of the self matches and half of the symmetric matches.\n",
    "\n",
    "Transitive matches create interesting \"chains\" of matches. Gaine has methods for eliminating them, which we won't dive into here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pkey_x != pkey_y gets rid of self matches (A = A)\n",
    "# pkey_x <= pkey_y gets rid of half the symmetric matches (allows A = B but not B = A)\n",
    "# pkey_x < pkey_y does both\n",
    "\n",
    "matches = matches[matches[\"pkey_x\"] < matches[\"pkey_y\"]]\n",
    "matches.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's display this in a stacked match report\n",
    "\n",
    "# Queued records\n",
    "queued = df.loc[matches[\"pkey_x\"]].drop_duplicates().reset_index()\n",
    "queued[\"record_src\"] = \"Queued\"\n",
    "queued[\"queued_pkey\"] = queued[\"pkey\"]\n",
    "\n",
    "# Candidate Records\n",
    "candidates = df.reset_index().merge(matches, how=\"inner\", left_on=\"pkey\", right_on=\"pkey_y\")\n",
    "candidates[\"record_src\"] = \"Candidate\"\n",
    "candidates[\"queued_pkey\"] = candidates[\"pkey_x\"]\n",
    "\n",
    "# Union them\n",
    "report = pd.concat([queued, candidates], sort=False)[[\"record_src\", \"queued_pkey\", \"pkey\", \"name\", \"address_line_1\", \"city\", \"region\", \"post_code\", \"oshpd_id\", \"cms_id\"]] \\\n",
    "    .sort_values(by=[\"queued_pkey\", \"record_src\"], ascending=[True, False])\n",
    "\n",
    "report.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "report.to_excel(\"report.xlsx\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
